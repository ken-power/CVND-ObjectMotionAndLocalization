{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sense and Move\n",
    "\n",
    "In this notebook, let's put all of what we've learned together and see what happens to an initial probability distribution as a robot goes trough cycles of sensing then moving then sensing then moving, and so on! Recall that each time a robot senses (in this case a red or green color)it gains information about its environment, and everytime it moves, it loses some information due to motion uncertainty.\n",
    "\n",
    "\n",
    "<img src='images/sense_move.png' width=50% height=50% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's include our usual resource imports and display function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function for visualizing a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_map(grid, bar_width=1):\n",
    "    if(len(grid) > 0):\n",
    "        x_labels = range(len(grid))\n",
    "        plt.bar(x_labels, height=grid, width=bar_width, color='b')\n",
    "        plt.xlabel('Grid Cell')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.ylim(0, 1) # range of 0-1 for probability values \n",
    "        plt.title('Probability of the robot being at each cell in the grid')\n",
    "        plt.xticks(np.arange(min(x_labels), max(x_labels)+1, 1))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Grid is empty')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### QUIZ: Given the list motions=[1,1], compute the posterior distribution if the robot first senses red, then moves right one, then senses green, then moves right again, starting with a uniform prior distribution, `p`.\n",
    "\n",
    "`motions=[1,1]` mean that the robot moves right one cell and then right again. You are given the initial variables and the complete `sense` and `move` function, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given initial variables\n",
    "p=[0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "# the color of each grid cell in the 1D world\n",
    "world=['green', 'red', 'red', 'green', 'green']\n",
    "# Z, the sensor reading ('red' or 'green')\n",
    "measurements = ['red', 'green']\n",
    "pHit = 0.6\n",
    "pMiss = 0.2\n",
    "\n",
    "motions = [1,1]\n",
    "pExact = 0.8\n",
    "pOvershoot = 0.1\n",
    "pUndershoot = 0.1\n",
    "\n",
    "# You are given the complete sense function\n",
    "def sense(p, Z):\n",
    "    ''' Takes in a current probability distribution, p, and a sensor reading, Z.\n",
    "        Returns a *normalized* distribution after the sensor measurement has been made, q.\n",
    "        This should be accurate whether Z is 'red' or 'green'. '''\n",
    "    q=[]\n",
    "    # loop through all grid cells\n",
    "    for i in range(len(p)):\n",
    "        # check if the sensor reading is equal to the color of the grid cell\n",
    "        # if so, hit = 1\n",
    "        # if not, hit = 0\n",
    "        hit = (Z == world[i])\n",
    "        q.append(p[i] * (hit * pHit + (1-hit) * pMiss))\n",
    "        \n",
    "    # sum up all the components\n",
    "    s = sum(q)\n",
    "    # divide all elements of q by the sum to normalize\n",
    "    for i in range(len(p)):\n",
    "        q[i] = q[i] / s\n",
    "    return q\n",
    "\n",
    "\n",
    "# The complete move function\n",
    "def move(p, U):\n",
    "    q=[]\n",
    "    # iterate through all values in p\n",
    "    for i in range(len(p)):\n",
    "        # use the modulo operator to find the new location for a p value\n",
    "        # this finds an index that is shifted by the correct amount\n",
    "        index = (i-U) % len(p)\n",
    "        nextIndex = (index+1) % len(p)\n",
    "        prevIndex = (index-1) % len(p)\n",
    "        s = pExact * p[index]\n",
    "        s = s + pOvershoot  * p[nextIndex]\n",
    "        s = s + pUndershoot * p[prevIndex]\n",
    "        # append the correct, modified value of p to q\n",
    "        q.append(s)\n",
    "    return q\n",
    "\n",
    "\n",
    "## TODO: Compute the posterior distribution if the robot first senses red, then moves \n",
    "## right one, then senses green, then moves right again, starting with a uniform prior distribution.\n",
    "\n",
    "## print/display that distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification about Entropy\n",
    "\n",
    "The video mentions that entropy will go down after the update step and that entropy will go up after the measurement step. \n",
    "\n",
    "In general, **entropy measures the amount of uncertainty**. Since the update step increases uncertainty, then entropy should increase. The measurement step decreases uncertainty, so entropy should decrease.\n",
    "\n",
    "Let's look at our current example where the robot could be at five different positions. The maximum uncertainty occurs when all positions have equal probabilities  $[0.2, 0.2, 0.2, 0.2, 0.2]$ \n",
    "\n",
    "Following the formula $$\\text{Entropy} = \\Sigma  (-p \\times log(p))$$we get $$-5 \\times (.2)\\times log(0.2) = 0.699$$\n",
    "\n",
    "Taking a measurement should decrease uncertainty and thus decrease entropy. Let's say after taking a measurement, the probabilities become <span class=\"mathquill\">[0.05, 0.05, 0.05, 0.8, 0.05]</span>. Now the entropy decreased to 0.338. Hence a measurement step should decrease entropy whereas an update step should increase entropy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
